{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd845979",
   "metadata": {},
   "source": [
    "### install pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8860066",
   "metadata": {},
   "source": [
    "### Import pandas and read Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Importera pandas\n",
    "import pandas as pd\n",
    "\n",
    "!pwd\n",
    "%cd \"../data\"\n",
    "# TODO: Ladda in data från CSV-fil\n",
    "df = pd.read_csv('winequality-red.csv')\n",
    "\n",
    "# TODO: Visa första 5 raderna\n",
    "df.head()\n",
    "\n",
    "# TODO: Visa antal rader och kolumner\n",
    "df.shape\n",
    "\n",
    "# TODO: Lista alla kolumner\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18252b9b",
   "metadata": {},
   "source": [
    "### plot for show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a5816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_outlier_data(df, columns):\n",
    "    n = len(columns)\n",
    "    fig, axes = plt.subplots(n, 1, figsize=(8, 3*n))  # en kolumn av subplots\n",
    "\n",
    "    for ax, col in zip(axes, columns):\n",
    "        ax.plot(df[col])\n",
    "        ax.set_title(col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "find_outlier_data(df, df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe8ef0",
   "metadata": {},
   "source": [
    "### check nan value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d6a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_nans=df.isna().sum()\n",
    "print(check_nans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d3755",
   "metadata": {},
   "source": [
    "### Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0348133",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Visa statistik för numeriska kolumner\n",
    "#print(df.describe())\n",
    "\n",
    "# TODO: Kolla efter outliers (extremvärden)\n",
    "df_test = (df.loc[:, df.columns != 'quality']).copy()\n",
    "# print(f\"total rows: {len(df)}\")\n",
    "\n",
    "# print(df_test.loc[:, df_test.columns != 'quality'])\n",
    "for col in df_test.columns:\n",
    "    Q1 = df_test[f\"{col}\"].quantile(0.25)\n",
    "    Q3 = df_test[f\"{col}\"].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    #print(f\"col: {col} --- IQR: {IQR} --- low: {lower_bound} --- high: {upper_bound}\")\n",
    "\n",
    "    outlier = df_test[(df_test[f\"{col}\"] > lower_bound) | (df_test[f\"{col}\"] < upper_bound)]\n",
    "    # print(\"Outliers:\\n\")\n",
    "print(outlier.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277a7c48",
   "metadata": {},
   "source": [
    "### Check dublicateds and drop duplicateds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Kolla efter duplikate\n",
    "dups=df.duplicated()\n",
    "print(dups)\n",
    "\n",
    "df=df.drop_duplicates()\n",
    "\n",
    "dropted_dups=df.duplicated()\n",
    "print(dropted_dups)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed014d07",
   "metadata": {},
   "source": [
    "### Show data with bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26cf2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bar_subplots(dataFrame, columns):\n",
    "    n = len(columns)\n",
    "    fig, axes = plt.subplots(n, 1, figsize=(8, 3*n))\n",
    "\n",
    "    for ax, col in zip(axes, columns):\n",
    "        ax.bar(dataFrame.index, dataFrame[col])\n",
    "        ax.set_title(col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "bar_subplots(df, df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d75f84",
   "metadata": {},
   "source": [
    "### show data with histogram chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbc531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def hist_subplots(df, columns):\n",
    "    n = len(columns)\n",
    "    fig, axes = plt.subplots(n, 1, figsize=(8, 3*n))\n",
    "    colors = ['red','blue','green','orange','purple','brown','orange','gray','cyan','magenta','yellow','black']\n",
    "    for ax, col,color in zip(axes, columns,colors):\n",
    "        ax.hist(df[col],bins=7, edgecolor='black', color=color, alpha=0.7)\n",
    "        ax.set_title(col,color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "hist_subplots(df, df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a86356",
   "metadata": {},
   "source": [
    "### Good quality wine data graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45bd8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_quality_wine = df[(df['quality'] >= 7.5)]\n",
    "good_quality_wine.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bar_subplots(good_quality_wine, good_quality_wine.columns)\n",
    "hist_subplots(good_quality_wine, good_quality_wine.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b291d",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20118694",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn\n",
    "\n",
    "print(\"✅ scikit-learn installerad!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d166456",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_curve, auc,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\" Bibliotek importerade!\")\n",
    "print(\"Vi använder sklearn - världens enklaste ML-bibliotek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9619dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\" VÄLJ DATA FÖR MODELLEN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TARGET (vad vi vill förutsäga)\n",
    "Y = df['quality']\n",
    "print(f\" Target (Y): quality\")\n",
    "print(f\"   → Detta ska modellen lära sig förutsäga\\n\")\n",
    "\n",
    "X = df.loc[:, df.columns != 'quality']\n",
    "\n",
    "print(f\"\\n Data shape:\")\n",
    "print(f\"   X: {X.shape} (rader, kolumner)\")\n",
    "print(f\"   Y: {Y.shape} (rader)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae923c5",
   "metadata": {},
   "source": [
    "### Classifing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9bf6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa en kategori:\n",
    "# 1 = hög temperatur\n",
    "# 0 = låg temperatur\n",
    "df[\"Good_quality\"] = (df[\"quality\"] > 6.5).astype(float)\n",
    "\n",
    "print(df[[\"quality\", \"Good_quality\"]].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a36d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clf =df[[df.loc[:, df.columns != 'quality']]]\n",
    "y_clf = df[['quality']]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x_clf, y_clf, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab6d42",
   "metadata": {},
   "source": [
    "### Logical regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eaa7117b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistisk regression\n",
      "Accuracy: 0.5367647058823529\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mLogistisk regression\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAccuracy:\u001b[39m\u001b[33m\"\u001b[39m, accuracy_score(Y_test, y_pred_log))\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m precision = \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_log\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m recall = recall_score(Y_test, y_pred_log)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPrecision:\u001b[39m\u001b[33m\"\u001b[39m, precision)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.14/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.14/site-packages/sklearn/metrics/_classification.py:2524\u001b[39m, in \u001b[36mprecision_score\u001b[39m\u001b[34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[39m\n\u001b[32m   2356\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   2357\u001b[39m     {\n\u001b[32m   2358\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   2383\u001b[39m     zero_division=\u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2384\u001b[39m ):\n\u001b[32m   2385\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[32m   2386\u001b[39m \n\u001b[32m   2387\u001b[39m \u001b[33;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2522\u001b[39m \u001b[33;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[32m   2523\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2524\u001b[39m     p, _, _, _ = \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2525\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2526\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2529\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprecision\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2531\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2533\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2534\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.14/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1996\u001b[39m, in \u001b[36mprecision_recall_fscore_support\u001b[39m\u001b[34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1827\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[32m   1828\u001b[39m \n\u001b[32m   1829\u001b[39m \u001b[33;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1993\u001b[39m \u001b[33;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[32m   1994\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1995\u001b[39m _check_zero_division(zero_division)\n\u001b[32m-> \u001b[39m\u001b[32m1996\u001b[39m labels = \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1998\u001b[39m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[32m   1999\u001b[39m samplewise = average == \u001b[33m\"\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1779\u001b[39m, in \u001b[36m_check_set_wise_labels\u001b[39m\u001b[34m(y_true, y_pred, average, labels, pos_label)\u001b[39m\n\u001b[32m   1777\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1778\u001b[39m             average_options.remove(\u001b[33m\"\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1779\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1780\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m but average=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m\u001b[33m. Please \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1781\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % (y_type, average_options)\n\u001b[32m   1782\u001b[39m         )\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[32m1\u001b[39m):\n\u001b[32m   1784\u001b[39m     warnings.warn(\n\u001b[32m   1785\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) is ignored when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1786\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maverage != \u001b[39m\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m\u001b[33m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m). You may use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1789\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m   1790\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    solver=\"liblinear\"   \n",
    ")\n",
    "log_reg.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "print(\"\\nLogistisk regression\")\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, y_pred_log))\n",
    "\n",
    "precision = precision_score(Y_test, y_pred_log)\n",
    "recall = recall_score(Y_test, y_pred_log)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_log = confusion_matrix(Y_test, y_pred_log)\n",
    "\n",
    "sns.heatmap(cm_log, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix – Logistic Regression\")\n",
    "plt.xlabel(\"Prediktion\")\n",
    "plt.ylabel(\"Sant värde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a4b7ee",
   "metadata": {},
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "rf_clf.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_rf_clf = rf_clf.predict(X_test)\n",
    "\n",
    "print(\"\\nRandom Forest Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, y_pred_rf_clf))\n",
    "precision = precision_score(y_true=Y_test, y_pred=y_pred_rf_clf,average='micro')\n",
    "recall = recall_score(y_true=Y_test, y_pred=y_pred_rf_clf, average='micro')\n",
    "\n",
    "print(\"\\nRandom Forest Regression\")\n",
    "print(\"R2:\", r2_score(Y_test, y_pred_rf_clf))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f9ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rf = confusion_matrix(Y_test, y_pred_rf_clf)\n",
    "\n",
    "sns.heatmap(cm_rf, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
    "plt.title(\"Confusion Matrix – Random Forest\")\n",
    "plt.xlabel(\"Prediktion\")\n",
    "plt.ylabel(\"Sant värde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45359589",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_clf.feature_importances_\n",
    "features = x_clf.columns\n",
    "\n",
    "df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "print(df.sort_values('Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3789a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(Y_test, y_pred_rf_clf, alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Real quality of the wine\")\n",
    "plt.ylabel(\"Predicted quality of the wine\")\n",
    "plt.title(\"Real vs predicted – quality of the wine\")\n",
    "\n",
    "# rita en linje som visar 'perfekta' prediktioner\n",
    "min_val = min(y_pred_rf_clf.min(), y_pred_rf_clf.min())\n",
    "max_val = max(y_pred_rf_clf.max(), y_pred_rf_clf.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='red', linewidth=2)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
